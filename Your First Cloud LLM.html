<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Infographic: The Gemma LLM Lab</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f0f4f8;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 320px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .flow-arrow {
            color: #0079FF;
            font-size: 2rem;
            line-height: 1;
        }
        .card {
            background-color: white;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            padding: 1.5rem;
            transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        }
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
        }
        .brand-dark-blue { color: #004AAD; }
        .brand-main-blue { color: #0079FF; }
        .brand-light-blue { color: #55A6FF; }
        .brand-lighter-blue { color: #99C9FF; }
        .brand-bg-blue { background-color: #CCE4FF; }
        .brand-bg-main-blue { background-color: #0079FF; }
    </style>
</head>
<body class="text-gray-800">

    <div class="container mx-auto p-4 sm:p-6 lg:p-8">

        <header class="text-center mb-12">
            <h1 class="text-4xl md:text-6xl font-black brand-dark-blue mb-2">Your First Cloud LLM</h1>
            <p class="text-xl md:text-2xl text-gray-600">A Visual Guide to the Gemma 2B-IT Lab</p>
            <div class="mt-6 flex justify-center items-center space-x-6">
                <div class="text-center">
                    <p class="text-3xl font-bold brand-main-blue">2B</p>
                    <p class="text-sm text-gray-500">Parameters</p>
                </div>
                <div class="text-center">
                    <p class="text-3xl font-bold brand-main-blue">T4</p>
                    <p class="text-sm text-gray-500">GPU</p>
                </div>
                <div class="text-center">
                    <p class="text-3xl font-bold brand-main-blue">100%</p>
                    <p class="text-sm text-gray-500">Cloud-Native</p>
                </div>
            </div>
        </header>

        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">The Mission Toolkit</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">This lab integrates several industry-standard tools. Understanding each component's role is key to grasping the modern ML development workflow.</p>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                <div class="card text-center">
                    <div class="text-5xl mb-3">‚òÅÔ∏è</div>
                    <h3 class="text-xl font-bold mb-2">Google Colab</h3>
                    <p class="text-gray-600">Your cloud-based Python environment with free access to a powerful T4 GPU.</p>
                </div>
                <div class="card text-center">
                    <div class="text-5xl mb-3">ü§ó</div>
                    <h3 class="text-xl font-bold mb-2">Hugging Face</h3>
                    <p class="text-gray-600">The central hub for accessing the Gemma model and managing your secure access token.</p>
                </div>
                <div class="card text-center">
                    <div class="text-5xl mb-3">ü§ñ</div>
                    <h3 class="text-xl font-bold mb-2">Transformers</h3>
                    <p class="text-gray-600">The essential Python library for loading, configuring, and interacting with the LLM.</p>
                </div>
                <div class="card text-center">
                    <div class="text-5xl mb-3">üíé</div>
                    <h3 class="text-xl font-bold mb-2">Gemma 2B-IT</h3>
                    <p class="text-gray-600">The lightweight, instruction-tuned language model from Google that you will run.</p>
                </div>
            </div>
        </section>
        
        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">The 5-Step Mission Flow</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">The lab follows a linear path from environment setup to final experimentation. Each step builds upon the last, culminating in successful model interaction.</p>
            <div class="flex flex-col items-center">
                <div class="card w-full max-w-2xl text-center mb-4">
                    <p class="brand-main-blue font-bold">STEP 1</p>
                    <h3 class="text-2xl font-bold">Setup & Authenticate</h3>
                    <p class="text-gray-600 mt-1">Configure the Colab T4 GPU and securely log in to Hugging Face using a `read` token stored in Colab Secrets.</p>
                </div>
                <div class="flow-arrow">‚ñº</div>
                <div class="card w-full max-w-2xl text-center my-4">
                    <p class="brand-main-blue font-bold">STEP 2</p>
                    <h3 class="text-2xl font-bold">Install & Load</h3>
                    <p class="text-gray-600 mt-1">Install the `transformers` and `accelerate` libraries. Load the Gemma tokenizer and the 2-billion-parameter model onto the GPU.</p>
                </div>
                <div class="flow-arrow">‚ñº</div>
                <div class="card w-full max-w-2xl text-center my-4">
                    <p class="brand-main-blue font-bold">STEP 3</p>
                    <h3 class="text-2xl font-bold">Generate Text</h3>
                    <p class="text-gray-600 mt-1">Create a `text-generation` pipeline and use the model's chat template to craft a well-formatted prompt for a coherent response.</p>
                </div>
                 <div class="flow-arrow">‚ñº</div>
                <div class="card w-full max-w-2xl text-center my-4">
                    <p class="brand-main-blue font-bold">STEP 4</p>
                    <h3 class="text-2xl font-bold">Experiment</h3>
                    <p class="text-gray-600 mt-1">Adjust inference parameters like `temperature` and `max_new_tokens` to observe their impact on the model's creativity and output length.</p>
                </div>
                 <div class="flow-arrow">‚ñº</div>
                <div class="card w-full max-w-2xl text-center mt-4">
                    <p class="brand-main-blue font-bold">STEP 5</p>
                    <h3 class="text-2xl font-bold">Collect Evidence</h3>
                    <p class="text-gray-600 mt-1">Capture a screenshot of your results and programmatically print the model's configuration to submit for grading.</p>
                </div>
            </div>
        </section>

        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">Deep Dive: Model Optimization</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">Running a 2-billion-parameter model on a free GPU is possible thanks to a key optimization: reducing memory precision. The lab uses `bfloat16`, which halves the model's VRAM footprint compared to the standard `float32` with negligible impact on performance.</p>
            <div class="card">
                <div class="chart-container">
                    <canvas id="memoryChart"></canvas>
                </div>
            </div>
        </section>

        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">The Art of the Prompt</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">Instruction-tuned models like Gemma 2B-IT are specifically trained to follow conversational formats. Using the official chat template is critical for getting high-quality, relevant answers instead of confusing, repetitive text.</p>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="card border-l-4 border-red-500">
                    <h3 class="text-xl font-bold mb-4">‚ùå The Wrong Way (Raw String)</h3>
                    <pre class="bg-gray-100 p-3 rounded-md text-sm overflow-x-auto"><code>raw_prompt = "Explain transfer learning."
outputs = pipe(raw_prompt)</code></pre>
                    <p class="mt-4 text-gray-600">The model may try to *complete* your sentence rather than *answering* it, leading to incoherent output.</p>
                </div>
                <div class="card border-l-4 border-green-500">
                    <h3 class="text-xl font-bold mb-4">‚úÖ The Right Way (Chat Template)</h3>
                    <pre class="bg-gray-100 p-3 rounded-md text-sm overflow-x-auto"><code>chat = [{"role": "user", "content": "..."}]
prompt = tokenizer.apply_chat_template(chat)
outputs = pipe(prompt)</code></pre>
                    <p class="mt-4 text-gray-600">This formats the input exactly as the model expects, triggering its instruction-following behavior for a clear response.</p>
                </div>
            </div>
        </section>
        
        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">Tuning the Output: Temperature</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">The `temperature` parameter controls the randomness of the model's output. A low temperature produces predictable, deterministic text, while a high temperature encourages creativity and diversity, but also increases the risk of nonsensical answers.</p>
            <div class="card">
                 <div class="chart-container">
                    <canvas id="temperatureChart"></canvas>
                </div>
            </div>
        </section>

        <section class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8 brand-dark-blue">Mission Success: Grading Breakdown</h2>
            <p class="max-w-3xl mx-auto text-center text-gray-600 mb-10">Your final grade is based on providing concrete evidence of successful model execution and thoughtful reflection on the lab's core concepts. The two main evidence components carry the most weight.</p>
            <div class="card">
                <div class="chart-container">
                    <canvas id="gradingChart"></canvas>
                </div>
            </div>
        </section>

    </div>

    <footer class="text-center p-6 bg-gray-800 text-white">
        <p>Infographic created to visualize the "Module 2 Lab Guide".</p>
        <p class="text-sm text-gray-400 mt-1">This is a non-interactive representation. All data is illustrative based on the lab document.</p>
    </footer>

    <script>
        const tooltipTitleCallback = (tooltipItems) => {
            const item = tooltipItems[0];
            let label = item.chart.data.labels[item.dataIndex];
            if (Array.isArray(label)) {
                return label.join(' ');
            }
            return label;
        };

        const wrapLabel = (label, maxLength = 16) => {
            if (label.length <= maxLength) {
                return label;
            }
            const words = label.split(' ');
            const lines = [];
            let currentLine = '';
            for (const word of words) {
                if ((currentLine + ' ' + word).trim().length > maxLength) {
                    lines.push(currentLine.trim());
                    currentLine = word;
                } else {
                    currentLine = (currentLine + ' ' + word).trim();
                }
            }
            if (currentLine) {
                lines.push(currentLine.trim());
            }
            return lines;
        };

        const colorPalette = {
            darkBlue: '#004AAD',
            mainBlue: '#0079FF',
            lightBlue: '#55A6FF',
            lighterBlue: '#99C9FF',
            bgBlue: '#CCE4FF',
            red: '#EF4444',
            green: '#22C55E'
        };

        new Chart(document.getElementById('memoryChart'), {
            type: 'bar',
            data: {
                labels: ['Standard Precision (float32)', 'Optimized Precision (bfloat16)'],
                datasets: [{
                    label: 'Approx. VRAM Usage (GB)',
                    data: [10.7, 5.4],
                    backgroundColor: [colorPalette.lightBlue, colorPalette.mainBlue],
                    borderColor: [colorPalette.mainBlue, colorPalette.darkBlue],
                    borderWidth: 2
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                indexAxis: 'y',
                scales: {
                    x: {
                        beginAtZero: true,
                        title: {
                            display: true,
                            text: 'Gigabytes (GB) of VRAM'
                        }
                    }
                },
                plugins: {
                    legend: {
                        display: false
                    },
                    title: {
                        display: true,
                        text: 'VRAM Footprint: float32 vs. bfloat16',
                        font: { size: 18 }
                    },
                    tooltip: {
                        callbacks: {
                           title: tooltipTitleCallback
                        }
                    }
                }
            }
        });

        new Chart(document.getElementById('temperatureChart'), {
            type: 'bar',
            data: {
                labels: ['Predictability', 'Creativity', 'Risk of Nonsense'],
                datasets: [
                    {
                        label: 'Low Temperature (e.g., 0.2)',
                        data: [9, 2, 1],
                        backgroundColor: colorPalette.lightBlue,
                        borderColor: colorPalette.mainBlue,
                        borderWidth: 1
                    },
                    {
                        label: 'High Temperature (e.g., 0.9)',
                        data: [3, 9, 6],
                        backgroundColor: colorPalette.mainBlue,
                        borderColor: colorPalette.darkBlue,
                        borderWidth: 1
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 10,
                        title: {
                            display: true,
                            text: 'Relative Score'
                        }
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'Effect of Temperature on Model Output',
                        font: { size: 18 }
                    },
                    tooltip: {
                        callbacks: {
                           title: tooltipTitleCallback
                        }
                    }
                }
            }
        });

        new Chart(document.getElementById('gradingChart'), {
            type: 'doughnut',
            data: {
                labels: [
                    wrapLabel('Evidence 1: Screenshot'),
                    wrapLabel('Evidence 2: Model Config'),
                    wrapLabel('Reflection Questions')
                ],
                datasets: [{
                    label: 'Points',
                    data: [40, 40, 20],
                    backgroundColor: [
                        colorPalette.mainBlue,
                        colorPalette.lightBlue,
                        colorPalette.lighterBlue
                    ],
                    borderColor: '#ffffff',
                    borderWidth: 3,
                    hoverOffset: 4
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        position: 'top',
                    },
                    title: {
                        display: true,
                        text: 'Grading Point Distribution (100 Total)',
                        font: { size: 18 }
                    },
                    tooltip: {
                        callbacks: {
                           title: tooltipTitleCallback
                        }
                    }
                }
            }
        });
    </script>
</body>
</html>
